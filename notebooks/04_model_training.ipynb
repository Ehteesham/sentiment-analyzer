{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from ensure import ensure_annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\CDAC\\\\Machine Learning\\\\sentiment-analyzer\\\\notebooks'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\CDAC\\\\Machine Learning\\\\sentiment-analyzer'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass(frozen=True)\n",
    "class ModelTrainingConfig:\n",
    "    model_dir: Path\n",
    "    train_data_file: Path\n",
    "    test_data_file: Path\n",
    "    # Model Parameters\n",
    "    C: float\n",
    "    max_iter: int\n",
    "    n_jobs: int\n",
    "    penalty: str\n",
    "    solver: str\n",
    "    class_weight: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentimentAnalyzer.constant import *\n",
    "from sentimentAnalyzer.utils.common import read_yaml, create_directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(self, config_path = CONFIG_FILE_PATH, params_path = PARAMS_FILE_PATH):\n",
    "        self.config = read_yaml(config_path)\n",
    "        self.params = read_yaml(params_path)\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "    def get_model_training_config(self) -> ModelTrainingConfig:\n",
    "        config = self.config.model_trainer\n",
    "        parmas = self.params.model_params\n",
    "        create_directories([config.model_dir])\n",
    "\n",
    "        model_trianing_config = ModelTrainingConfig(\n",
    "            model_dir = Path(config.model_dir),\n",
    "            train_data_file = Path(config.train_data_file),\n",
    "            test_data_file = Path(config.test_data_file),\n",
    "\n",
    "            C = parmas.C,\n",
    "            max_iter = parmas.max_iter,\n",
    "            n_jobs = parmas.n_jobs,\n",
    "            penalty = parmas.penalty,\n",
    "            solver = parmas.solver,\n",
    "            class_weight = parmas.class_weight\n",
    "        )\n",
    "\n",
    "        return model_trianing_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sentimentAnalyzer.utils.common import load_transformed_data_file, DataInfo\n",
    "from sentimentAnalyzer.logging import logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelTraining:\n",
    "    def __init__(self, config: ModelTrainingConfig):\n",
    "        self.config = config\n",
    "\n",
    "    def train_model(self):\n",
    "        X_train, y_train = load_transformed_data_file(path=self.config.train_data_file, \n",
    "                                               data_info=DataInfo.TRAINING)\n",
    "        \n",
    "        X_test, y_test = load_transformed_data_file(path=self.config.test_data_file,\n",
    "                                                    data_info=DataInfo.TESTING)\n",
    "        \n",
    "        # Getting Model Parameters\n",
    "        C = self.config.C\n",
    "        max_iter = self.config.max_iter\n",
    "        n_jobs = self.config.n_jobs\n",
    "        penalty = self.config.penalty\n",
    "        solver = self.config.solver\n",
    "        class_weight = self.config.class_weight\n",
    "\n",
    "\n",
    "        lrmodel = LogisticRegression(C = C, \n",
    "                                     max_iter=max_iter, \n",
    "                                     n_jobs=n_jobs, \n",
    "                                     penalty=penalty, \n",
    "                                     solver=solver, \n",
    "                                     class_weight=class_weight)\n",
    "        # Model Training\n",
    "        lrmodel.fit(X_train, y_train)\n",
    "        logger.info(\"Model Training Completed\")\n",
    "        # Classification Report for now\n",
    "        y_pred = lrmodel.predict(X_test)\n",
    "        print(f\">>>>>>> Classifiaction Report <<<<<<< \\n{classification_report(y_test, y_pred)}\")\n",
    "\n",
    "        # Saving the Model\n",
    "        if self.config.model_dir.exists():\n",
    "            joblib.dump(lrmodel, f\"{self.config.model_dir}/trained_model.pkl\")\n",
    "            logger.info(f'Trained Model is Saved in {self.config.model_dir}')\n",
    "        else:\n",
    "            logger.info(\"Directory not found and model not Saved\")\n",
    "            raise FileNotFoundError(\"Directory is Not Found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-01-04 19:13:43,653: INFO: common: yaml file: config\\config.yaml loaded successfully]\n",
      "[2025-01-04 19:13:43,654: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2025-01-04 19:13:43,654: INFO: common: created directory at: artifacts]\n",
      "[2025-01-04 19:13:43,654: INFO: common: created directory at: artifacts/train_model]\n",
      "[2025-01-04 19:13:45,121: INFO: common: Input Transformed Training Data has been load from artifacts\\data_transformation\\train\\X_train.npz]\n",
      "[2025-01-04 19:13:45,148: INFO: common: Output Transformed Training Data is load from artifacts\\data_transformation\\train\\y_train.npy]\n",
      "[2025-01-04 19:13:45,693: INFO: common: Input Transformed Testing Data has been load from artifacts\\data_transformation\\test\\X_test.npz]\n",
      "[2025-01-04 19:13:45,721: INFO: common: Output Transformed Testing Data is load from artifacts\\data_transformation\\test\\y_test.npy]\n",
      "[2025-01-04 19:14:37,271: INFO: 174323616: Model Training Completed]\n",
      ">>>>>>> Classifiaction Report <<<<<<< \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.78      0.79    159494\n",
      "           1       0.79      0.81      0.80    160506\n",
      "\n",
      "    accuracy                           0.80    320000\n",
      "   macro avg       0.80      0.80      0.80    320000\n",
      "weighted avg       0.80      0.80      0.80    320000\n",
      "\n",
      "[2025-01-04 19:14:37,437: INFO: 174323616: Trained Model is Saved in artifacts\\train_model]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    model_training_config = config.get_model_training_config()\n",
    "    model_training = ModelTraining(config=model_training_config)\n",
    "    model_training.train_model()\n",
    "except Exception as e:\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from enum import Enum\n",
    "from box.exceptions import BoxValueError\n",
    "import yaml\n",
    "from sentimentAnalyzer.logging import logger\n",
    "from ensure import ensure_annotations\n",
    "from box import ConfigBox\n",
    "from pathlib import Path\n",
    "from typing import Any, Union\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import save_npz, load_npz, csr_matrix\n",
    "from sentimentAnalyzer.utils.common import DataInfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ensure_annotations\n",
    "def load_transformed_data_file(path: Path, data_info: DataInfo) -> tuple:\n",
    "    \"\"\"\n",
    "    Load transformed input and output data from files in a directory.\n",
    "\n",
    "    Args:\n",
    "        path (Path): Path to the directory containing transformed data files.\n",
    "        data_info (DataInfo): Metadata about whether this data is for training or testing.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary with keys \"input\" (csr_matrix) and \"output\" (np.ndarray).\n",
    "              Example:\n",
    "              {\n",
    "                  \"input\": <csr_matrix>,\n",
    "                  \"output\": <ndarray>\n",
    "              }\n",
    "\n",
    "    Raises:\n",
    "        FileNotFoundError: If the directory does not contain any valid files.\n",
    "        ValueError: If a file has an unsupported extension.\n",
    "\n",
    "    Notes:\n",
    "        - The function expects at least one `.npz` file (for input data) and one `.npy` file\n",
    "          (for output data) in the provided directory.\n",
    "        - If the directory is empty, an exception is raised.\n",
    "        - Unsupported file extensions will result in a ValueError.\n",
    "    \"\"\"\n",
    "\n",
    "    path_file_lst = list(path.glob(\"*\"))\n",
    "    result_dic = dict()\n",
    "\n",
    "    if not path_file_lst:\n",
    "        logger.info(f\"{path_file_lst} does not exist\")\n",
    "        raise FileNotFoundError(f\"File not found: {path_file_lst}\")\n",
    "    \n",
    "    for file_path in path_file_lst:\n",
    "        \n",
    "        if file_path.suffix == \".npz\":\n",
    "            data = load_npz(file_path)\n",
    "            result_dic[\"input\"] = data\n",
    "            logger.info(f\"Input {data_info.value} has been load from {file_path}\")\n",
    "        elif file_path.suffix == \".npy\":\n",
    "            data = np.load(file_path)\n",
    "            result_dic['output'] = data\n",
    "            logger.info(f\"Output {data_info.value} is load from {file_path}\")\n",
    "        else:\n",
    "            logger.info(f\"{file_path} file extension not supported\")\n",
    "            raise ValueError(f\"Unsupported file extension: {file_path.suffix}\")\n",
    "    \n",
    "    return result_dic.get('input'), result_dic.get('output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-01-04 16:52:18,836: INFO: 2216929817: Input Transformed Training Data has been load from artifacts\\data_transformation\\train\\X_train.npz]\n",
      "[2025-01-04 16:52:18,836: INFO: 2216929817: Output Transformed Training Data is load from artifacts\\data_transformation\\train\\y_train.npy]\n",
      "[2025-01-04 16:52:19,074: INFO: 2216929817: Input Transformed Testing Data has been load from artifacts\\data_transformation\\test\\X_test.npz]\n",
      "[2025-01-04 16:52:19,076: INFO: 2216929817: Output Transformed Testing Data is load from artifacts\\data_transformation\\test\\y_test.npy]\n"
     ]
    }
   ],
   "source": [
    "a, b = load_transformed_data_file(Path(\"artifacts/data_transformation/train\"), data_info=DataInfo.TRAINING)\n",
    "c, d = load_transformed_data_file(Path(\"artifacts/data_transformation/test\"), data_info=DataInfo.TESTING)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse._csr.csr_matrix"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = a.get('input')\n",
    "y_train = a.get('output')\n",
    "X_test = b.get('input')\n",
    "y_test = b.get('output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_evaluation(model):\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(f\">>>>>>> Classifiaction Report <<<<<<< \\n{classification_report(y_test, y_pred)}\")\n",
    "    cf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    print(f\">>>>>>> Confusion Matrix <<<<<< \\n {cf_matrix}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.78      0.79    159494\n",
      "           1       0.79      0.81      0.80    160506\n",
      "\n",
      "    accuracy                           0.80    320000\n",
      "   macro avg       0.80      0.80      0.80    320000\n",
      "weighted avg       0.80      0.80      0.80    320000\n",
      "\n",
      "[[124162  35332]\n",
      " [ 30129 130377]]\n"
     ]
    }
   ],
   "source": [
    "lrmodel = LogisticRegression(C = 2, max_iter=1000, n_jobs=-1, penalty='l2', solver='saga', class_weight='balanced')\n",
    "lrmodel.fit(X_train, y_train)\n",
    "model_evaluation(lrmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Compressed Sparse Row sparse matrix of dtype 'float64'\n",
       "\twith 12996765 stored elements and shape (1280000, 300000)>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 0, 0, 0], shape=(1280000,))"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_evaluation(model):\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    cf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    print(cf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WindowsPath('artifacts/data_transformation/train/X_train.npz'),\n",
       " WindowsPath('artifacts/data_transformation/train/y_train.npy')]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_paths = list(path.glob(\"*\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WindowsPath('artifacts/data_transformation/train/X_train.npz'), WindowsPath('artifacts/data_transformation/train/y_train.npy')]\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "No files found in directory: [WindowsPath('artifacts/data_transformation/train/X_train.npz'), WindowsPath('artifacts/data_transformation/train/y_train.npy')]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[43], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file_paths:\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(file_paths)\n\u001b[1;32m----> 3\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo files found in directory: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_paths\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: No files found in directory: [WindowsPath('artifacts/data_transformation/train/X_train.npz'), WindowsPath('artifacts/data_transformation/train/y_train.npy')]"
     ]
    }
   ],
   "source": [
    "if file_paths:\n",
    "    print(file_paths)\n",
    "    raise FileNotFoundError(f\"No files found in directory: {file_paths}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'exists'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[45], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m a \u001b[38;5;241m=\u001b[39m \u001b[43mload_transformed_data_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43martifacts/data_transformation/train\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDataInfo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTRAINING\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\CDAC\\Machine Learning\\sentiment-analyzer\\env\\Lib\\site-packages\\ensure\\main.py:872\u001b[0m, in \u001b[0;36mWrappedFunctionReturn.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    869\u001b[0m         msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mArgument \u001b[39m\u001b[38;5;132;01m{arg}\u001b[39;00m\u001b[38;5;124m of type \u001b[39m\u001b[38;5;132;01m{valt}\u001b[39;00m\u001b[38;5;124m to \u001b[39m\u001b[38;5;132;01m{f}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdoes not match annotation type \u001b[39m\u001b[38;5;132;01m{t}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    870\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m EnsureError(msg\u001b[38;5;241m.\u001b[39mformat(arg\u001b[38;5;241m=\u001b[39marg, f\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf, t\u001b[38;5;241m=\u001b[39mtempl, valt\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mtype\u001b[39m(value)))\n\u001b[1;32m--> 872\u001b[0m return_val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    873\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(return_val, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_templ):\n\u001b[0;32m    874\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReturn value of \u001b[39m\u001b[38;5;132;01m{f}\u001b[39;00m\u001b[38;5;124m of type \u001b[39m\u001b[38;5;132;01m{valt}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdoes not match annotation type \u001b[39m\u001b[38;5;132;01m{t}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
      "Cell \u001b[1;32mIn[44], line 21\u001b[0m, in \u001b[0;36mload_transformed_data_file\u001b[1;34m(path, data_info)\u001b[0m\n\u001b[0;32m     18\u001b[0m path_file_lst \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(path\u001b[38;5;241m.\u001b[39mglob(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m     19\u001b[0m result_dic \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m()\n\u001b[1;32m---> 21\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mpath_file_lst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexists\u001b[49m():\n\u001b[0;32m     22\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_file_lst\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not exist\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile not found: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_file_lst\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'exists'"
     ]
    }
   ],
   "source": [
    "a = load_transformed_data_file(Path(\"artifacts/data_transformation/train\"), data_info=DataInfo.TRAINING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataIngestion:\n",
    "    def __init__(self, config: ModelTrainingConfig):\n",
    "        self.config = config\n",
    "\n",
    "    def train_model(self):\n",
    "        pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
